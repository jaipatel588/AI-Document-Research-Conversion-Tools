from pathlib import Path
import json
from backend.app.services.vector_service import build_faiss_index_from_texts
import sys

sys.path.append(str(Path(__file__).resolve().parents[1]))
# -------------------------------
# âœ… File Paths
# -------------------------------
DATA_DIR = Path("backend/data")
DOC_STORE_FILE = DATA_DIR / "doc_store.txt"
METADATA_FILE = DATA_DIR / "metadata.json"

# -------------------------------
# âœ… Load Documents
# -------------------------------
def load_documents() -> list[str]:
    if not DOC_STORE_FILE.exists():
        raise FileNotFoundError(f"âŒ Document file not found: {DOC_STORE_FILE}")
    with DOC_STORE_FILE.open("r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

# -------------------------------
# âœ… Load Metadata
# -------------------------------
def load_metadata() -> list[str]:
    if not METADATA_FILE.exists():
        raise FileNotFoundError(f"âŒ Metadata file not found: {METADATA_FILE}")
    with METADATA_FILE.open("r", encoding="utf-8") as f:
        return json.load(f)

# -------------------------------
# âœ… Main Runner
# -------------------------------
if __name__ == "__main__":
    print("ğŸ“¦ Loading documents and metadata...")
    documents = load_documents()
    metadata = load_metadata()

    print(f"ğŸ“„ Documents loaded: {len(documents)}")
    print(f"ğŸ§¾ Metadata entries: {len(metadata)}")

    print("ğŸš€ Building FAISS index...")
    build_faiss_index_from_texts(documents, metadata)
    print("âœ… All done!")